<!DOCTYPE html>
<!-- Using url=(0041)https://cs.nyu.edu/~fouhey/NYCVision2025/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    

    <title>London GenAI Meetup: Frontiers and Applications 2025</title>

    <meta name="author" content="Pradyumna">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="https://cs.nyu.edu/~fouhey/NYCVision2025/images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="./index_files/stylesheet.css">
    
  </head>

  <body data-new-gr-c-s-check-loaded="14.1226.0" data-gr-ext-installed="">
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  London GenAI Forum 2025
                </p> 

                <br><br>

                <iframe
  src="https://lu.ma/embed/event/evt-GbGChe59H6u6pDd/simple"
  width="800"
  height="450"
  frameborder="0"
  style="border: 1px solid #bfcbda88; border-radius: 4px;"
  allowfullscreen=""
  aria-hidden="false"
  tabindex="0"
></iframe>

<br><br>

                <p>
                  The GenAI Forum at UCL brings together leading researchers and practitioners to explore cutting-edge developments in GenAI. The two-hour evening session features talks from prominent academics and industry experts, showcasing the latest breakthroughs in 3D generative modeling, 3D scene understanding, and other applications. This will be followed by a one-hour session for networking.</p>

              <p>
                
<b>Date and Time:</b> April 15, 2025 5PM - 8PM<br> 
<b>Location:</b> <a href="https://maps.app.goo.gl/4GCJYDwCf8qLeSYd8">University College London</a><br>   <!--UPDATE -->
<b>Address:</b> Gower St, London WC1E 6BT<br> <!--UPDATE -->
<b>Directions:</b> <a href="https://geometry.cs.ucl.ac.uk/">Directions to Geometry Lab building</a><br> <!--UPDATE -->
<!-- <b>Lead Organizer:</b> <a href="https://cs.nyu.edu/~fouhey/">David Fouhey</a><br> -->
<b>Advisory Committee:</b> <span><a href="http://www0.cs.ucl.ac.uk/staff/n.mitra/index.html">Niloy J. Mitra</a>, <a href="https://www.research.autodesk.com/people/hooman-shayani/">Hooman Shayani </a></span><br>
<!-- <b>Program Committee:</b> <span id="commit"><a href="https://mahis.life/">Mahi Shafiullah</a>, <a href="https://sjabbour.github.io/">Sarah Jabbour</a>, <a href="https://sunniesuhyoung.github.io/">Sunnie S.Y. Kim</a>, <a href="https://liuzhuang13.github.io/">Zhuang Liu</a>, <a href="https://ruoshiliu.github.io/">Ruoshi Liu</a></span><br> -->
<b>Organization Committee:</b> <a href="https://mfischer-ucl.github.io/">Michael Fischer</a>, <a href="https://niladridutt.com/">Niladri Shekhar Dutt</a>, <a href="https://preddy5.github.io/">Pradyumna Reddy</a><br>
<b>Youtube live:</b> <a href="https://youtube.com/">Will be updated</a><br>

<br>
<b>Attendance Information:</b> Please register <a href="https://lu.ma/0hkiwjeu" target="_blank">here</a> to get the tickets. Current details are tentative and will be updated by March 22.

</p>


              </td>
              <!-- <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="./index_files/icon.png"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="icon" src="./index_files/icon.png" class="hoverZoomLink"></a>
              </td> -->
            </tr>
          </tbody></table>

          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Tentative Schedule</h2>
                <p>
                </p>
              </td>
            </tr>
          </tbody></table>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


    <tr>
      <td colspan="2" style="text-align:center; width:100%">
        <!-- <h3>Casual Conversations and Coffee: 9:30AM â€” 10:00AM</h3> -->
        Doors will open just after 5PM to give time to get settled in with some coffee
      </td>
   </tr>

    <tr><td><br><br><br><br></td></tr>


    <tr>
      <td colspan="2" style="text-align:center; width:100%">
        <h3>Talk Session 1: 5:10PM â€” 5:35PM</h3>
      </td>
   </tr>

   <tr bgcolor="#d0ffd0">
    <td style="padding:16px;width:20%;vertical-align:middle">
          <img src="./index_files/placeholder.webp" width="150">
    </td>
    <td style="padding:8px;width:80%;vertical-align:middle">
      <p style="font-size:125%">
      <b>ðŸ’Ž Keynote 1:</b> Name 1
      </p>
      <p>
      Assistant Professor, University 1<br><br>
      <b>Topic 1: Editing 3D Objects Multimodal Foundation Models</b><br><br>
      3D generative modeling is a cutting-edge field that uses machine learning algorithms to create complex and realistic three-dimensional structures from data. Techniques such as Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and implicit neural representations enable the synthesis of detailed 3D objects, environments, and animations. This technology is widely applied in industries like gaming, architecture, and digital art, allowing for procedural content generation and AI-driven design. 
          </p>
    </td>
  </tr>

  <tr><td><br><br><br><br></td></tr>


  <tr>
    <td colspan="2" style="text-align:center; width:100%">
      <h3>Talk Session 2: 5:35PM â€” 6:00PM</h3>
    </td>
 </tr>

 <tr bgcolor="#ab82c5">
  <td style="padding:16px;width:20%;vertical-align:middle">
        <img src="./index_files/placeholder2.webp" width="150">
  </td>
  <td style="padding:8px;width:80%;vertical-align:middle">
    <p style="font-size:125%">
    <b>ðŸ’Ž Keynote 2:</b> Name 2
    </p>
    <p>
    Research Scientist, Company 1<br><br>
    <b>Topic 2: Generation 3D Objects Multimodal Foundation Models</b><br><br>
    By learning from existing 3D data, generative models can produce new variations, enhance creativity, and automate aspects of 3D modeling that traditionally require extensive manual effort. As advancements in deep learning continue, 3D generative modeling is becoming increasingly powerful and accessible, pushing the boundaries of virtual and augmented reality experiences. Recent advancements in 3D generative modeling have led to more efficient and scalable methods for creating high-quality assets with minimal human intervention. Neural implicit representations, such as Neural Radiance Fields (NeRFs), allow for highly detailed 3D reconstructions from limited input data. 
    </p>
  </td>
</tr>

<tr><td><br><br><br><br></td></tr>



<tr>
  <td colspan="2" style="text-align:center; width:100%">
    <h3>Talk Session 3: 6:00PM â€” 6:25PM</h3>
  </td>
</tr>

<tr bgcolor="#d0ffd0">
  <td style="padding:16px;width:20%;vertical-align:middle">
      <img src="./index_files/placeholder.webp" width="150">
</td>
<td style="padding:8px;width:80%;vertical-align:middle">
  <p style="font-size:125%">
  <b>ðŸ’Ž Keynote 3:</b> Name 3
  </p>
  <p>
    Professor, University 2<br><br>
  <b>Topic 3: Reasoning 3D Objects Multimodal Foundation Models</b><br><br>
  Additionally, diffusion models and transformer-based architectures are emerging as powerful tools for generating complex 3D structures with fine-grained control. These innovations are revolutionizing industries like virtual production, medical imaging, and digital twin simulations. As research continues, the integration of physics-based constraints and real-time generation will further enhance the realism and applicability of 3D generative models.
  </p>
</td>
</tr>

<tr><td><br><br><br><br></td></tr>

<tr>
  <td colspan="2" style="text-align:center; width:100%">
    <h3>âš¡ Lightning Talk Sessions: 6:25PM â€” 6:45PM</h3>
  </td>
</tr>

   <tr bgcolor="#ffffd0"><td>
    </td><td>
<!-- <p style="font-size:125%">âš¡ Lightning Talk Session</p> -->

<ol>
<li>Placeholder1: Text describing work 1</li>
<li>Placeholder2 (<a href="https://www.google.com">website</a>): Text describing work 2</li>
<li>Placeholder3: Text describing work 3 </li>

</ol>


    </td></tr>

    <tr><td><br></td></tr>


    <!-- <tr><td><br><br><br><br></td></tr> -->
    <tr><td><br></td></tr>

    <tr bgcolor="#d0d0d0">
      <td colspan="2" style="padding:16px;width:20%;vertical-align:middle;text-align:center;font-size:150%&#39;">
          <h3>Networking, Q&A 1 hour: food, drinks, discussions</h3>
      </td>
    </tr>


    <!-- <tr><td><br><br><br><br></td></tr>

    <tr>
      <td colspan="2" style="text-align:center; width:100%">
        <h3>ðŸ¥ª Lunch and ðŸª§ Poster Session 1: 11:30 â€” 1:30PM</h3>
        We'll have posters from 35 of the 75+ attending labs, and ample
        time for casual conversation.<br><br>
        <a href="https://docs.google.com/spreadsheets/d/1tDzoPAggXwn4KFRRE3sX7PhQLnHR7Vf_-FImQof-jmI/edit?usp=sharing">Link to Poster Session Ids</a>
      </td>
   </tr>

    <tr><td><br><br><br><br></td></tr> -->

<!-- 
   <tr>
      <td colspan="2" style="text-align:center; width:100%">
        <h3>Talk Session 2: 1:30PM â€” 4:30PM</h3>
      </td>
   </tr>



    <tr bgcolor="#ab82c5">
      <td style="padding:16px;width:20%;vertical-align:middle">
            <img src="./index_files/juan.jpg" width="150">
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <p style="font-size:125%">
        <b>ðŸ’Ž Welcoming Remarks:</b> Juan De Pablo
        </p>
        <p>
        Executive Vice President for Global Science and Technology, New York University<br>
        Executive Dean of the NYU Tandon School of Engineering<br>
        New York University
        </p>
      </td>
    </tr>


    <tr><td><br><br><br><br></td></tr>

   <tr bgcolor="#ffffd0"><td>
    </td><td>
<p style="font-size:125%">âš¡ Lightning Talk Session 2</p>

<ol>
<li>Jiuhong Xiao, NYU (<a href="https://xjh19971.github.io/">website</a>): Learning Visual Geo-Localization (<a href="https://xjh19971.github.io/STHN/">paper</a>)</li>
<li>Ilya Chugunov, Princeton (<a href="https://ilyac.info/">website</a>): Neural Light Spheres for Implicit Image Stitching and View Synthesis (<a href="https://light.princeton.edu/neuls">paper</a>)</li>
<li>Sihang Li, NYU (<a href="https://louis-leee.github.io/">website</a>): Unleashing the Power of Data Synthesis in Visual Localization (<a href="https://ai4ce.github.io/RAP/">paper</a>)</li>
<li>Chris Rockwell, NYU (<a href="https://crockwell.github.io/">website</a>): Dynamic Camera Poses and Where to Find Them</li>
<li>Liyan Chen, Stevens: Learning the distribution of errors in stereo matching for joint disparity and uncertainty estimation</li>
<li>Ran Gong, NYU: Differentiable Textured Surfel Octree as an Efficient 3D Scene Representation</li>
<li>Hyoungseob Park, Yale: AugUndo: Scaling Up Augmentations for Monocular Depth Completion and Estimation</li>
<li>Nhan Tran, Cornell (<a href="https://nhantran.com/">website</a>): Personal Time-Lapse (<a href="https://mecapture.com/">paper</a>)</li>
<li>Jiawei Liu, CUNY: SMDAF: A Scalable Sidewalk Material Data Acquisition Framework with Bidirectional Cross-Modal Knowledge Distillation</li>
<li>Rao Fu, Brown (<a href="https://freddierao.github.io/">website</a>): GigaHands: A Massive Annotated Dataset of Bimanual Hand Activities (<a href="https://ivl.cs.brown.edu/research/gigahands.html">paper</a>)</li>
<li>Moinak Bhattacharya, Stony Brook (<a href="https://sites.google.com/stonybrook.edu/moinakbhattacharya">website</a>): Eye Gaze-driven Medical Image Analysis</li>
<li>Rangel Daroya, UMass: WildSAT: Learning Satellite Image Representations from Wildlife Observations</li>
</ol>


    </td></tr>
    <tr><td><br></td></tr>

    <tr bgcolor="#d0d0d0">
      <td colspan="2" style="padding:16px;width:20%;vertical-align:middle;text-align:center;font-size:150%&#39;">
          <h3>Brief Break</h3>
      </td>
    </tr>


    <tr><td><br></td></tr>

    <tr bgcolor="#d0ffd0">
      <td style="padding:16px;width:20%;vertical-align:middle">
            <img src="./index_files/yunzhu.jpg" width="150">
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <p style="font-size:125%">
        <b>ðŸ’Ž Keynote 2:</b> Yunzhu Li
        </p>
        <p>
        Assistant Professor, Columbia University<br>
        <b>Foundation Models for Robotic Manipulation: Opportunities and Challenges</b><br><br>
In this talk, I will discuss the opportunities for incorporating foundation models into classic robotic pipelines to endow robots with capabilities beyond those achievable with traditional robotic tools. The central idea behind this research is to translate the commonsense knowledge embedded in foundation models into structural priors that can be integrated into robot learning systems. I will demonstrate how such integration enables robots to interpret instructions provided in free-form natural language to handle a wide range of real-world manipulation tasks. Toward the end of the talk, I will discuss the limitations of the current foundation models, challenges that still lie ahead, and potential avenues to address these challenges.
        
        </p>
      </td>
    </tr>


    <tr><td><br></td></tr>

   <tr bgcolor="#ffffd0"><td>
    </td><td>
<p style="font-size:125%">âš¡ Lightning Talk Session 3</p>

<ol>
<li>Yihong Sun, Cornell (<a href="https://yihongsun.github.io/">website</a>): Video Creation by Demonstration (<a href="https://delta-diffusion.github.io/">paper</a>)</li>
<li>Yunxiang Zhang, NYU (<a href="https://yunxiangzhang.github.io/">website</a>): GazeFusion: Saliency-Guided Image Generation (<a href="https://www.immersivecomputinglab.org/publication/gazefusion-saliency-guided-image-generation/">paper</a>)</li>
<li>Ye Zhu, Princeton (<a href="https://l-yezhu.github.io/">website</a>): Generative dynamics for image control and beyond</li>
<li>Alexander Raistrick, Princeton (<a href="https://araistrick.com/">website</a>): Infinigen Indoors: Photorealistic Indoor Scenes using Procedural Generation (<a href="https://infinigen.org/">paper</a>)</li>
<li>Qinhong Zhou, UMass (<a href="https://zhouqqhh.github.io/">website</a>): Virtual Community: A Generative Social World for Embodied AI (<a href="https://sites.google.com/view/virtual-community-simulation">paper</a>)</li>
<li>Saumya Gupta, Stony Brook (<a href="https://saumya-gupta-26.github.io/">website</a>): TopoDiffusionNet: A Topology-aware Diffusion Model (<a href="https://arxiv.org/abs/2410.16646">paper</a>)</li>
<li>Courtney King, Fordham: Efficient Occluded Object Detection Using Scene Context</li>
<li>Yuan Zang, Brown: Pre-trained Vision-Language Models Learn Discoverable Visual Concepts</li>
<li>Morris Alper, Cornell (<a href="https://morrisalp.github.io/">website</a>): Emergent Visual-Semantic Hierarchies in Image-Text Representations (<a href="https://tau-vailab.github.io/hierarcaps/">paper</a>)</li>
<li>Hritam Basak, Stony Brook (<a href="https://hritam-98.github.io/">website</a>): Forget More to Learn More: Domain-specific Feature Unlearning for Semi-supervised and Unsupervised Domain Adaptation (<a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/05513.pdf">paper</a>)</li>
<li>Matthew Chan, University of Maryland (<a href="https://www.cs.umd.edu/~mattchan/">website</a>): HyperDM: Estimating Epistemic and Aleatoric Uncertainty with a Single Model (<a href="https://github.com/matthewachan/hyperdm">paper</a>)</li>
<li>Willis Ma, NYU (<a href="https://willisma.github.io/">website</a>): Inference Time Scaling for Diffusion Models beyond Scaling Denoising Steps (<a href="https://inference-scale-diffusion.github.io/">paper</a>)</li>
</ol>


    </td></tr>


    <tr><td><br><br><br><br></td></tr>

    <tr>
      <td colspan="2" style="text-align:center; width:100%">
        <h3>ðŸª§ Poster Session 2: 4:30PM - 6:00PM</h3>
        We'll have posters from 35 of the 75+ attending labs, and ample
        time for casual conversation.<br><br>
        <a href="https://docs.google.com/spreadsheets/d/1tDzoPAggXwn4KFRRE3sX7PhQLnHR7Vf_-FImQof-jmI/edit?usp=sharing">Link to Poster Session Ids</a>
      </td>
   </tr> -->

    <tr><td><br><br><br><br></td></tr>

<script>
let advise = ['Niloy J. Mitra','Hooman Shayani'];
let adviseWeb = ['https://www.cs.columbia.edu/~vondrick/','https://www.research.autodesk.com/people/hooman-shayani/'];
let commit = ['Zhuang Liu', 'Sarah Jabbour', 'Mahi Shafiullah', 'Sunnie S.Y. Kim', 'Ruoshi Liu'];
let commitWeb = ['https://liuzhuang13.github.io/', 'https://sjabbour.github.io/', 'https://mahis.life/', 'https://sunniesuhyoung.github.io/', 'https://ruoshiliu.github.io/'];

let adviseStub = [];
for(let i=0; i < advise.length; i++){
    adviseStub.push("<a href='"+adviseWeb[i]+"'>"+advise[i]+"</a>");
}
let commitStub = [];
for(let i=0; i < commit.length; i++){
    commitStub.push("<a href='"+commitWeb[i]+"'>"+commit[i]+"</a>");
}

/* https://stackoverflow.com/questions/2450954/how-to-randomize-shuffle-a-javascript-array */
function shuffleArray(array) {
    for (var i = array.length - 1; i > 0; i--) {
        var j = Math.floor(Math.random() * (i + 1));
        var temp = array[i];
        array[i] = array[j];
        array[j] = temp;
    }
}
shuffleArray(adviseStub);
shuffleArray(commitStub);

document.getElementById('advise').innerHTML = adviseStub.join(", ");
document.getElementById('commit').innerHTML = commitStub.join(", ");
</script>


          
    </tbody></table><table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>
            <tr>
              <td>
                <h2>Host Information</h2>
              </td>
            </tr><tr>
               <td style="align:center;width:100%"> </td>
            </tr><tr>
               <td style="align:center;width:100%">
<br>
London GenAI Meetup: Frontiers and Applications 2025 is hosted by, and would not be possible without the generous backing and support of the 
<a href="https://www.adobe.com">Adobe</a>, <a href="https://www.autodesk.com">Autodesk</a>, <a href="https://ucl.ac.uk">University College London</a>.<br><br>
                <!-- We are grateful for additional support from 
<a href="https://engineering.nyu.edu/academics/departments/electrical-and-computer-engineering">NYU Electrical and Computer Engineering.</a><br> -->
<!--            <a href='https://engineering.nyu.edu/'><img src='logos/tandon.png' height=100></a><br/></td>-->
            </td></tr>
    </tbody></table>
    <table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>
            <tr>
              <td>
                <h2>Sponsors</h2>
              </td>
            </tr><tr>
               <td style="align:center;width:100%"> </td>
            </tr><tr>
            <td>
            <br>
            We gratefully acknowledge the support of(ordered alphabetically):<br><br>
            <img height="55" src="./index_files/adobe.png" alt="logo of Adobe"> &nbsp; 
            <img height="55" src="./index_files/autodesk.jpg" alt="logo of Autodesk"> &nbsp; 
            <img height="55" src="./index_files/ucl.png" alt="logo of UCL"> &nbsp; <br>
            </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <!-- 
            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
                <div class="colored-box" style="background-color: #ADD8E6;"><h2>Diamond</h2></div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
              </td>
            </tr>

            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
                <div class="colored-box" style="background-color: #E5E4E2;"><h2>Platinum</h2></div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
              </td>
            </tr>


            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
                <div class="colored-box" style="background-color: #FFD700;"><h2>&nbsp;&nbsp;&nbsp;&nbsp;Gold&nbsp;&nbsp;&nbsp;&nbsp;</h2></div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
              </td>
            </tr>
            -->

            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                Thank you to <a href="https://jonbarron.info/">Jon Barron</a> for the website template<br>
                Brooklyn Bridge Photo Courtesy of <a href="https://en.wikipedia.org/wiki/Brooklyn_Bridge#/media/File:Brooklyn_Bridge_-_03.jpg">Carlos Delgado</a>
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </tbody></table>
  

</body></html>